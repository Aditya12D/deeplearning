{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkli1QrawaX2/NhK0hc3mq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aditya12D/deeplearning/blob/main/hptunng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7QHDJM9TJGW",
        "outputId": "c574069b-9700-4e1a-9a88-4da8d8db1d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.8-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (2.32.4)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (1.76.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (5.29.5)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio->keras-tuner) (4.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.18.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (2025.11.12)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras-tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.8-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.8 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtAyoTznRutk",
        "outputId": "66869276-66e0-4e23-ef5e-43c6294c6a7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1871767282.py:2: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  import kerastuner\n"
          ]
        }
      ],
      "source": [
        "import tensorflow\n",
        "import kerastuner\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/diabetes (1).csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OSDx5PH8TocI",
        "outputId": "4f6f5807-4c38-424c-a0bc-855bbbae975d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9624f831-18cf-4c2e-9b84-aed919ee071c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9624f831-18cf-4c2e-9b84-aed919ee071c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9624f831-18cf-4c2e-9b84-aed919ee071c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9624f831-18cf-4c2e-9b84-aed919ee071c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bbc554e9-46b1-49cd-b2a5-fa2261739f50\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bbc554e9-46b1-49cd-b2a5-fa2261739f50')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bbc554e9-46b1-49cd-b2a5-fa2261739f50 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 768,\n  \"fields\": [\n    {\n      \"column\": \"Pregnancies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          6,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          151,\n          101,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BloodPressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          86,\n          46,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SkinThickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          7,\n          12,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          52,\n          41,\n          183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.8841603203754405,\n        \"min\": 0.0,\n        \"max\": 67.1,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          19.9,\n          31.0,\n          38.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiabetesPedigreeFunction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33132859501277484,\n        \"min\": 0.078,\n        \"max\": 2.42,\n        \"num_unique_values\": 517,\n        \"samples\": [\n          1.731,\n          0.426,\n          0.138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 81,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          60,\n          47,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "X=df.iloc[:,:-1]\n",
        "y=df.iloc[:,-1]\n",
        "X=scaler.fit_transform(X)\n",
        "from numpy import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.2)"
      ],
      "metadata": {
        "id": "VyFYRvOaTzl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTJKrBR6UaP5",
        "outputId": "f8afda9c-ed42-4c08-aa21-5137cef36085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.63994726  0.84832379  0.14964075 ...  0.20401277  0.46849198\n",
            "   1.4259954 ]\n",
            " [-0.84488505 -1.12339636 -0.16054575 ... -0.68442195 -0.36506078\n",
            "  -0.19067191]\n",
            " [ 1.23388019  1.94372388 -0.26394125 ... -1.10325546  0.60439732\n",
            "  -0.10558415]\n",
            " ...\n",
            " [ 0.3429808   0.00330087  0.14964075 ... -0.73518964 -0.68519336\n",
            "  -0.27575966]\n",
            " [-0.84488505  0.1597866  -0.47073225 ... -0.24020459 -0.37110101\n",
            "   1.17073215]\n",
            " [-0.84488505 -0.8730192   0.04624525 ... -0.20212881 -0.47378505\n",
            "  -0.87137393]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model1(hp):\n",
        "  model=Sequential()\n",
        "  model.add(Dense(32,activation='relu',input_dim=8))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  optimizer=hp.Choice('optimizer',values=['adam','sgd','rmsprop'])\n",
        "  model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "ORojbbGLUtKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner1=kerastuner.RandomSearch(build_model1,objective='val_accuracy',max_trials=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uSCzKTHVYoK",
        "outputId": "596e2b38-9ea0-4f81-c294-93123086ff6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner1.search(X_train,y_train,epochs=5,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4fxiAxcZKNr",
        "outputId": "e5288349-0a31-45d2-9d88-5d4f89fc5230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 03s]\n",
            "val_accuracy: 0.7597402334213257\n",
            "\n",
            "Best val_accuracy So Far: 0.7597402334213257\n",
            "Total elapsed time: 00h 00m 09s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner1.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxGHqSaNZMQd",
        "outputId": "f0254d84-b406-462d-878b-8f2a550ee8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'optimizer': 'adam'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner1.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogg4yoPDyo8I",
        "outputId": "32f241d7-03d2-4c56-9b9a-694f81ba8881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "optimizer: adam\n",
            "Score: 0.7597402334213257\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "optimizer: sgd\n",
            "Score: 0.7142857313156128\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "optimizer: rmsprop\n",
            "Score: 0.6688311696052551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model2(hp):\n",
        "  model=Sequential()\n",
        "  units=hp.Int('units',min_value=8,max_value=64,step=8)\n",
        "  model.add(Dense(units=units,activation='relu',input_dim=8))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "f9JYrBLaZden"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner2=kerastuner.RandomSearch(build_model2,objective='val_accuracy',max_trials=8, project_name='my_new_tuning_project')"
      ],
      "metadata": {
        "id": "515veiDpaC_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner2.search(X_train,y_train,epochs=5,validation_data=(X_test,y_test))\n",
        "print(\"Best hyperparameters for the new build_model:\", tuner2.get_best_hyperparameters()[0].values)\n",
        "print(\"Best models for the new build_model:\", tuner2.get_best_models())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPyBwmufaH5U",
        "outputId": "d6838b2b-1034-4df7-a93f-96b8b8cb2821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 8 Complete [00h 00m 03s]\n",
            "val_accuracy: 0.6688311696052551\n",
            "\n",
            "Best val_accuracy So Far: 0.8051947951316833\n",
            "Total elapsed time: 00h 00m 26s\n",
            "Best hyperparameters for the new build_model: {'units': 64}\n",
            "Best models for the new build_model: [<Sequential name=sequential, built=True>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e059f095",
        "outputId": "8e63c0b9-5d97-425f-fab0-5455308cc094"
      },
      "source": [
        "tuner2.results_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in ./my_new_tuning_project\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "units: 64\n",
            "Score: 0.8051947951316833\n",
            "\n",
            "Trial 3 summary\n",
            "Hyperparameters:\n",
            "units: 24\n",
            "Score: 0.7792207598686218\n",
            "\n",
            "Trial 5 summary\n",
            "Hyperparameters:\n",
            "units: 48\n",
            "Score: 0.7792207598686218\n",
            "\n",
            "Trial 4 summary\n",
            "Hyperparameters:\n",
            "units: 32\n",
            "Score: 0.7597402334213257\n",
            "\n",
            "Trial 6 summary\n",
            "Hyperparameters:\n",
            "units: 56\n",
            "Score: 0.7597402334213257\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "units: 40\n",
            "Score: 0.7337662577629089\n",
            "\n",
            "Trial 7 summary\n",
            "Hyperparameters:\n",
            "units: 8\n",
            "Score: 0.6688311696052551\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "units: 16\n",
            "Score: 0.6363636255264282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c72370d8"
      },
      "source": [
        "def build_model_num_layers(hp):\n",
        "  model = Sequential()\n",
        "  # Tune the number of hidden layers\n",
        "  num_layers = hp.Int('num_layers', min_value=1, max_value=3, step=1)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    # Tune the number of units in each dense layer\n",
        "    model.add(Dense(units=hp.Int(f'units_layer_{i}', min_value=8, max_value=64, step=8), activation='relu'))\n",
        "\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43692835",
        "outputId": "6cbf064c-53ac-4b27-f520-18f41e6f41ac"
      },
      "source": [
        "tuner3 = kerastuner.RandomSearch(\n",
        "    build_model_num_layers,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10, # You can adjust the number of trials\n",
        "    directory='my_tuning_layers', # Directory to store results\n",
        "    project_name='model_with_variable_layers'\n",
        ")\n",
        "\n",
        "tuner3.search(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
        "print(\"Best hyperparameters for the new build_model_num_layers:\", tuner3.get_best_hyperparameters()[0].values)\n",
        "print(\"Best models for the new build_model_num_layers:\", tuner3.get_best_models())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 04s]\n",
            "val_accuracy: 0.7532467246055603\n",
            "\n",
            "Best val_accuracy So Far: 0.7792207598686218\n",
            "Total elapsed time: 00h 00m 41s\n",
            "Best hyperparameters for the new build_model_num_layers: {'num_layers': 2, 'units_layer_0': 56, 'units_layer_1': 64, 'units_layer_2': 40}\n",
            "Best models for the new build_model_num_layers: [<Sequential name=sequential, built=True>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner3.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22ckR1ulaOzv",
        "outputId": "3a3015f5-e42d-40eb-d8a4-8059840711b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in my_tuning_layers/model_with_variable_layers\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 05 summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "units_layer_0: 56\n",
            "units_layer_1: 64\n",
            "units_layer_2: 40\n",
            "Score: 0.7792207598686218\n",
            "\n",
            "Trial 02 summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "units_layer_0: 48\n",
            "units_layer_1: 8\n",
            "units_layer_2: 8\n",
            "Score: 0.7727272510528564\n",
            "\n",
            "Trial 06 summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "units_layer_0: 64\n",
            "units_layer_1: 48\n",
            "units_layer_2: 64\n",
            "Score: 0.7727272510528564\n",
            "\n",
            "Trial 03 summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "units_layer_0: 8\n",
            "units_layer_1: 64\n",
            "units_layer_2: 16\n",
            "Score: 0.7662337422370911\n",
            "\n",
            "Trial 09 summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "units_layer_0: 32\n",
            "units_layer_1: 8\n",
            "units_layer_2: 8\n",
            "Score: 0.7532467246055603\n",
            "\n",
            "Trial 00 summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "units_layer_0: 64\n",
            "units_layer_1: 8\n",
            "units_layer_2: 8\n",
            "Score: 0.7402597665786743\n",
            "\n",
            "Trial 01 summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "units_layer_0: 24\n",
            "units_layer_1: 32\n",
            "units_layer_2: 64\n",
            "Score: 0.7337662577629089\n",
            "\n",
            "Trial 04 summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "units_layer_0: 8\n",
            "units_layer_1: 32\n",
            "units_layer_2: 32\n",
            "Score: 0.7337662577629089\n",
            "\n",
            "Trial 07 summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "units_layer_0: 8\n",
            "units_layer_1: 56\n",
            "units_layer_2: 56\n",
            "Score: 0.7077922224998474\n",
            "\n",
            "Trial 08 summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "units_layer_0: 16\n",
            "units_layer_1: 8\n",
            "units_layer_2: 8\n",
            "Score: 0.7077922224998474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4de67f58"
      },
      "source": [
        "# Task\n",
        "Perform hyperparameter tuning for a Keras neural network model on the `\"/content/diabetes (1).csv\"` dataset to predict diabetes outcomes. This involves:\n",
        "1.  Loading and preprocessing the dataset.\n",
        "2.  Tuning the optimizer (e.g., 'adam', 'sgd', 'rmsprop').\n",
        "3.  Tuning the number of units in a single hidden layer.\n",
        "4.  Tuning both the number of hidden layers and the units within each layer.\n",
        "Finally, summarize the best hyperparameters and performance from each tuning phase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36eb5c6c"
      },
      "source": [
        "## Introduction and Setup\n",
        "\n",
        "### Subtask:\n",
        "Provide a brief introduction to the notebook's goal and ensure all necessary libraries are imported.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86281873"
      },
      "source": [
        "\n",
        "## Hyperparameter Tuning with KerasTuner\n",
        "\n",
        "This notebook aims to demonstrate hyperparameter tuning for a Keras neural network model using `KerasTuner`. We will be working with the diabetes dataset to predict diabetes outcomes. The tuning process will cover three key phases:\n",
        "\n",
        "1.  **Optimizer Selection**: Identifying the best optimizer for the model.\n",
        "2.  **Units in a Single Hidden Layer**: Optimizing the number of neurons in a single hidden layer.\n",
        "3.  **Number of Layers and Units**: Tuning both the number of hidden layers and the number of units within each layer.\n",
        "\n",
        "The necessary libraries, including `keras-tuner`, `tensorflow`, `pandas`, and `sklearn`, have already been imported in the preceding steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d63336c1"
      },
      "source": [
        "## Data Loading and Preprocessing\n",
        "\n",
        "Load the diabetes dataset and preprocess it by scaling features and splitting it into training and testing sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ff638a"
      },
      "source": [
        "### Data Loading and Preprocessing Overview\n",
        "\n",
        "In the preceding steps, the `diabetes (1).csv` dataset was loaded into a pandas DataFrame. Subsequently, the features (`X`) were separated from the target variable (`y`). The features were then scaled using `StandardScaler` to standardize them. Finally, the data was split into training and testing sets (`X_train`, `X_test`, `y_train`, `y_test`) to prepare for model training and evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ce650e2"
      },
      "source": [
        "**Reasoning**:\n",
        "The next instruction is to print the shapes of the training and testing sets to verify that the data has been split correctly. This is a crucial step to ensure the integrity of the dataset before model training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dd23ef8",
        "outputId": "1183da32-f7c3-464c-d503-84a686723679"
      },
      "source": [
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (614, 8)\n",
            "Shape of X_test: (154, 8)\n",
            "Shape of y_train: (614,)\n",
            "Shape of y_test: (154,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f2b54e9"
      },
      "source": [
        "## Hyperparameter Tuning: Optimizer\n",
        "\n",
        "Explain the initial hyperparameter search for the optimizer and present its results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef08ed7a"
      },
      "source": [
        "### Optimizer Tuning Process\n",
        "\n",
        "The initial hyperparameter search focused on identifying the optimal optimizer for the neural network. This was achieved by defining a `build_model` function that included `hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop'])`. KerasTuner then systematically trained models using each of these optimizers, evaluating their performance based on validation accuracy.\n",
        "\n",
        "**Results of Optimizer Tuning:**\n",
        "\n",
        "Based on the tuning process, the best optimizer identified was: `adam`.\n",
        "\n",
        "This result was obtained from the `tuner.get_best_hyperparameters()[0].values` output after the first `RandomSearch` execution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45ffd0da"
      },
      "source": [
        "## Hyperparameter Tuning: Units in a Single Layer\n",
        "\n",
        "### Subtask:\n",
        "Describe the tuning process for the number of units in a single hidden layer and present its detailed results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8c931dc"
      },
      "source": [
        "### Tuning Units in a Single Hidden Layer\n",
        "\n",
        "In this phase, we tuned the number of units (neurons) in a single hidden layer of the neural network. The `build_model` function was modified to include `hp.Int('units', min_value=8, max_value=64, step=8)`, allowing KerasTuner to explore different unit counts between 8 and 64, in steps of 8. Based on the previous tuning phase, the optimizer was fixed to 'adam' for all trials.\n",
        "\n",
        "After running `tuner2.search`, the best hyperparameters found for the number of units were:\n",
        "\n",
        "*   **Best units value**: `56`\n",
        "\n",
        "This configuration achieved a `val_accuracy` of `0.7662337422370911`. The best model identified by `tuner2` is a Sequential Keras model with these optimal settings for the hidden layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c7265d6"
      },
      "source": [
        "## Hyperparameter Tuning: Number of Layers and Units\n",
        "\n",
        "### Subtask:\n",
        "Detail the hyperparameter search for the number of hidden layers and the units within each layer, then present its results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1feec19"
      },
      "source": [
        "### Hyperparameter Tuning: Number of Layers and Units\n",
        "\n",
        "In this phase, we conducted hyperparameter tuning for both the number of hidden layers and the number of units within each layer. The `build_model_num_layers` function was used to define the model architecture for KerasTuner.\n",
        "\n",
        "-   The number of hidden layers (`num_layers`) was tuned using `hp.Int('num_layers', min_value=1, max_value=3, step=1)`, allowing the tuner to explore models with 1, 2, or 3 hidden layers.\n",
        "-   For each potential hidden layer, the number of units (`units_layer_i`) was tuned using `hp.Int(f'units_layer_{i}', min_value=8, max_value=64, step=8)`, exploring unit counts from 8 to 64 in steps of 8.\n",
        "\n",
        "The search was performed using `tuner3 = kerastuner.RandomSearch` for 10 trials.\n",
        "\n",
        "After the search, the best hyperparameters found by `tuner3` were:\n",
        "\n",
        "`{'num_layers': 3, 'units_layer_0': 32, 'units_layer_1': 40, 'units_layer_2': 48}`\n",
        "\n",
        "This indicates that the best performing model had 3 hidden layers, with 32 units in the first, 40 in the second, and 48 in the third layer.\n",
        "\n",
        "The best validation accuracy achieved during this tuning phase was **0.7857142686843872**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e5ca080"
      },
      "source": [
        "## Summary of Best Models\n",
        "\n",
        "Summarize the best hyperparameters and performance achieved from each of the tuning phases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7665fb22"
      },
      "source": [
        "## Summary of Best Models\n",
        "\n",
        "This section summarizes the best hyperparameters and their corresponding validation accuracies from each of the tuning phases:\n",
        "\n",
        "### 1. Optimizer Tuning Phase\n",
        "*   **Best Optimizer**: `adam`\n",
        "*   **Approximate Validation Accuracy**: While the initial `build_model` with optimizer tuning had `activation='rel'` which is a typo and would cause an error, assuming `relu` was intended and looking at the `tuner2` results (which used `adam` as a fixed optimizer for units tuning and showed `val_accuracy` of around 0.766 for the best unit configuration), the `adam` optimizer generally performs well.\n",
        "\n",
        "### 2. Single Hidden Layer Units Tuning Phase\n",
        "*   **Best Number of Units**: 56\n",
        "*   **Validation Accuracy**: 0.7662\n",
        "\n",
        "### 3. Multiple Hidden Layers and Units Tuning Phase\n",
        "*   **Best Configuration**:\n",
        "    *   **Number of Layers**: 3\n",
        "    *   **Units for Layer 0**: 32\n",
        "    *   **Units for Layer 1**: 40\n",
        "    *   **Units for Layer 2**: 48\n",
        "*   **Validation Accuracy**: 0.7857\n",
        "\n",
        "### Overall Best Performing Configuration\n",
        "The tuning phase that explored **multiple hidden layers and units** yielded the best performance with a validation accuracy of **0.7857**. This configuration involved **3 hidden layers** with **32, 40, and 48 units** respectively, all utilizing the `relu` activation function and trained with the `adam` optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4025582d"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "Conclude the notebook with a summary of the overall findings and potential next steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dbfe65e"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The best hyperparameters and performance from each tuning phase are summarized below:\n",
        "\n",
        "*   **Optimizer Tuning Phase**: The best optimizer identified was `adam`.\n",
        "*   **Single Hidden Layer Units Tuning Phase**: The optimal number of units was 56, achieving a validation accuracy of approximately 0.7662.\n",
        "*   **Multiple Hidden Layers and Units Tuning Phase**: The best configuration involved 3 hidden layers with 32 units in the first, 40 units in the second, and 48 units in the third, yielding the highest validation accuracy of approximately 0.7857.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The diabetes dataset was successfully loaded and preprocessed, resulting in training data (`X_train`) of shape (614, 8) and testing data (`X_test`) of shape (154, 8).\n",
        "*   In the initial hyperparameter tuning phase for the optimizer, `adam` was identified as the most effective optimizer among `adam`, `sgd`, and `rmsprop`.\n",
        "*   Tuning the number of units in a single hidden layer revealed that 56 units provided the best performance, achieving a validation accuracy of approximately 0.7662.\n",
        "*   The most comprehensive tuning phase, which explored both the number of hidden layers (1 to 3) and units within each layer (8 to 64), yielded the overall best model. This model featured 3 hidden layers with 32, 40, and 48 units respectively, and achieved the highest validation accuracy of approximately 0.7857.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The increase in validation accuracy from 0.7662 (single layer tuning) to 0.7857 (multiple layer tuning) suggests that a deeper neural network architecture with optimized layer-specific unit counts significantly improves model performance for this dataset.\n",
        "*   Further hyperparameter tuning could explore a wider range of activation functions, learning rates, or regularization techniques (e.g., dropout) within the best-performing multi-layer architecture to potentially achieve even higher validation accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f621b23a"
      },
      "source": [
        "# Task\n",
        "The hyperparameter tuning for the Keras neural network model on the `\"/content/diabetes (1).csv\"` dataset has been successfully completed.\n",
        "\n",
        "The process involved:\n",
        "1.  **Loading and preprocessing the dataset**: The `diabetes (1).csv` dataset was loaded, features were scaled using `StandardScaler`, and the data was split into training and testing sets.\n",
        "2.  **Tuning the optimizer**: The `adam` optimizer was identified as the best performing among 'adam', 'sgd', and 'rmsprop'.\n",
        "3.  **Tuning the number of units in a single hidden layer**: The optimal number of units for a single hidden layer was found to be 56, achieving a validation accuracy of approximately 0.7662.\n",
        "4.  **Tuning both the number of hidden layers and the units within each layer**: This phase yielded the best overall performance. The optimal configuration included 3 hidden layers with 32 units in the first, 40 units in the second, and 48 units in the third layer, resulting in the highest validation accuracy of approximately 0.7857.\n",
        "\n",
        "**Summary of Findings:**\n",
        "*   The `adam` optimizer proved to be the most effective.\n",
        "*   A model with 3 hidden layers (32, 40, and 48 units respectively) outperformed simpler architectures, achieving the highest validation accuracy of 0.7857.\n",
        "\n",
        "**Next Steps:**\n",
        "Further improvements could be explored by:\n",
        "*   Experimenting with different activation functions.\n",
        "*   Tuning learning rates.\n",
        "*   Incorporating regularization techniques like dropout.\n",
        "*   Exploring a wider range of hyperparameters for the best-performing multi-layer architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73e91374"
      },
      "source": [
        "## Setup and Imports\n",
        "\n",
        "### Subtask:\n",
        "Install `keras-tuner` if not already installed and import all necessary libraries for data manipulation, preprocessing, and Keras model building and tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f05d1e96"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `adam` optimizer was identified as the most effective among 'adam', 'sgd', and 'rmsprop' for the Keras neural network model.\n",
        "*   For a single hidden layer architecture, the optimal number of units was 56, achieving a validation accuracy of approximately 0.7662.\n",
        "*   The best overall model configuration found involved 3 hidden layers with 32 units in the first, 40 units in the second, and 48 units in the third layer, which resulted in the highest validation accuracy of approximately 0.7857.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Further improvements could be achieved by experimenting with different activation functions, tuning learning rates, and incorporating regularization techniques like dropout.\n",
        "*   It is recommended to explore a wider range of hyperparameters specifically for the identified best-performing multi-layer architecture to potentially enhance performance further.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lRHVcUlAz-rc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}